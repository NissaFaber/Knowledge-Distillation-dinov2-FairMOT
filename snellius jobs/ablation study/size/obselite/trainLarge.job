#!/bin/bash

#SBATCH --partition=gpu
#SBATCH --gpus=1
#SBATCH --job-name=checkTrain
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=18
#SBATCH --time=10:00:00
#SBATCH --output=slurm_output_%A.out

module purge
module load 2023
module load Anaconda3/2023.07-2



# Activate your environment
source activate mot
# Check whether the GPU is available
cd repo/Thesis/src

echo start training

srun python -u train.py mot  --arch hrnet_18 --gpus 0 --load_model '/home/nfaber/repo/models/hrnetv2_w18_imagenet_pretrained.pth' --data_cfg '../src/lib/cfg/mot17.json' --num_epochs '10' --batch_size 3 --num_workers 2 --pretrainedHrnet True --dinov2 large --alpha 0.75
echo done

